{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125dcf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projekti/nelma/mondoDB/parse_thai_name.py:23: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  title_male = re.compile('^นาย|เด็กชาย|ด\\.ช\\.|สยา')\n",
      "/projekti/nelma/mondoDB/parse_thai_name.py:24: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  title_female = re.compile('^นาง|นางสาว|เด็กหญิง|ด\\.ญ\\.|น\\.ส\\.')\n",
      "/projekti/nelma/mondoDB/parse_thai_name.py:27: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  title_company = re.compile('บริษัท|ห้างหุ้นส่วนจำกัด|หจก\\.|ร้าน')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['douglas adams']) {'tokens': ['davor', 'lauc'], 'labels': ('fn1_hr_Latn_HR', 'ln_hr_Latn_HR'), 'prob': 92.0626} {'tokens': ['반', '기문'], 'labels': ('ln_ko_Hang_KR', 'fn1_ko_Hang_KR'), 'prob': 97.0899}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94, ['it', 'fr', 'de', 'en'], ['en'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from wiki_labels import qid_lab_get, qid_en_desc_get\n",
    "from wiki_location import q2cc\n",
    "from text_utils import cl\n",
    "import sys\n",
    "sys.path.insert(0, '/projekti/mondoAPI')\n",
    "from pnu.parse import parse\n",
    "from api.db import db\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "sys.path.insert(0, '/projekti/nelma')\n",
    "sys.path.insert(0, '/projekti/nelma/mondoDB')\n",
    "\n",
    "from mondoDB.parse_thai_name import norm_thai, tokenise, parse_thai\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from wikilang2iso import wikil2cc, cc2lang, iso2w, w2iso\n",
    "\n",
    "print(qid_lab_get(42, 'en').keys(), parse('davor lauc')['tags'][0], parse('반기문')['tags'][0])\n",
    "wikil2cc['Q1860']['US'], cc2lang['CH'], cc2lang['US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecf37331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e21e126993409f84f167b84b19ff82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17630406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('US', 15.4)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wikilang2iso import get_wiki_cc, cc_weights\n",
    "\n",
    "for i, l in tqdm(enumerate(gzip.open('/backup/wikidata/wikinelma.jsonl.gz')), total=26_074_182):\n",
    "    j = json.loads(l)\n",
    "    if j['type'] == 'per':\n",
    "        qid = int(j['wiki_id'][1:])\n",
    "        cc, ccs = get_wiki_cc({k: v for k, v in j in k in cc_weights})\n",
    "        break \n",
    "ccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01fc0aa7-4d92-491b-a25a-680dcfd90682",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m notable \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/backup/wikidata/cross-verified-database.csv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m qrank \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwikidata_code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mranking_visib_5criteria\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnotable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      4\u001b[0m notable\n",
      "File \u001b[0;32m/projekti/venv312/lib/python3.12/site-packages/pandas/core/frame.py:1542\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1540\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1542\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1544\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/projekti/venv312/lib/python3.12/site-packages/pandas/core/series.py:593\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    590\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n\u001b[1;32m    592\u001b[0m NDFrame\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data)\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_axis(\u001b[38;5;241m0\u001b[39m, index)\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_pandas_object \u001b[38;5;129;01mand\u001b[39;00m data_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n",
      "File \u001b[0;32m/projekti/venv312/lib/python3.12/site-packages/pandas/core/generic.py:6317\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6314\u001b[0m \u001b[38;5;66;03m# if this fails, go on to more involved attribute setting\u001b[39;00m\n\u001b[1;32m   6315\u001b[0m \u001b[38;5;66;03m# (note that this matches __getattr__, above).\u001b[39;00m\n\u001b[1;32m   6316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set:\n\u001b[0;32m-> 6317\u001b[0m     \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6318\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata:\n\u001b[1;32m   6319\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n",
      "File \u001b[0;32m/projekti/venv312/lib/python3.12/site-packages/pandas/core/series.py:780\u001b[0m, in \u001b[0;36mSeries.name\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m    Return the name of the Series.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m    'Even Numbers'\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name\n\u001b[0;32m--> 780\u001b[0m \u001b[38;5;129m@name\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     validate_all_hashable(value, error_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "notable = pd.read_csv('/backup/wikidata/cross-verified-database.csv.gz', compression='gzip', encoding='latin-1')\n",
    "pd.set_option('display.max_columns', None)\n",
    "qrank = {v['wikidata_code']:v['ranking_visib_5criteria'] for _, v in notable.iterrows()}\n",
    "notable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = gzip.open('/backup/wikidata/wiki_person.tsv.gz', 'wt')\n",
    "fo.write('qid\\tname\\tfn\\tln\\tgender\\tcc_first\\tnative_lang\\tccs\\tdesc_en\\tdesc_nl\\tdob\\tdod\\timage\\tsort\\n')\n",
    "for i, l in tqdm(enumerate(gzip.open('/backup/wikidata/wikinelma.jsonl.gz')), total=25_042_218):\n",
    "    j = json.loads(l)\n",
    "    if j['type'] == 'per':\n",
    "        qid = int(j['wiki_id'][1:])\n",
    "        cc, ccs = get_wiki_cc({k: v for k, v in j if k in cc_weights})\n",
    "        name = None\n",
    "        if j['native_language']:\n",
    "            langs = Counter([iso2w[q[5:]] for q in j['native_language'] if q[5:] in iso2w])\n",
    "        else:\n",
    "            langs = Counter()\n",
    "        langs.update(cc2lang[cc])\n",
    "        native_lang = langs.most_common()[0][0] if langs else ''\n",
    "        if '-' in native_lang:\n",
    "            native_lang = native_lang.split('-')[0]\n",
    "        elif len(native_lang)>2:\n",
    "            native_lang = native_lang[:2]\n",
    "        if j['name_native']:\n",
    "            name = cl(j['name_native'][0]).lower()\n",
    "        else:\n",
    "            for l, f in langs.most_common():\n",
    "                name = qid_lab_get(qid, l)\n",
    "                if name:\n",
    "                    name = list(name)[0]\n",
    "                    break\n",
    "        if not name:\n",
    "            try:\n",
    "                name = list(qid_lab_get(qid, 'en', include_alt=False).keys())[0]\n",
    "            except:\n",
    "                try:\n",
    "                    name = list(j['l'].values())[0][0]\n",
    "                except:\n",
    "                    name = ''\n",
    "        if name:\n",
    "            namel = name.lower().strip()\n",
    "            desc = qid_en_desc_get(qid)\n",
    "            dob = j['dob'][0][:4] if j['dob'] else ''\n",
    "            dod = j['dod'][0][:4] if 'dod' in j and j['dod'] else ''\n",
    "            \n",
    "            image = j['picture'][0] if j['picture'] else ''\n",
    "            sort = qrank[j['wiki_id']] if  j['wiki_id'] in qrank  else (100_000_000+(int(dob) if dob else 1980)-(50 if image else 0)-(10 if desc else 0))\n",
    "\n",
    "            fn = ''\n",
    "            if j['fn']:\n",
    "                fns = qid_lab_get(int(j['fn'][0][6:]), include_alt=True).keys()\n",
    "                fns = Counter({a:len(a) for a in fns if a in namel})\n",
    "                if len(fns)>0:\n",
    "                    fn = fns.most_common()[0][0]\n",
    "\n",
    "            ln = ''\n",
    "            if j['ln']:\n",
    "                fns = qid_lab_get(int(j['ln'][0][6:]), include_alt=True).keys()\n",
    "                fns = Counter({a:len(a) for a in fns if a in namel})\n",
    "                if len(fns)>0:\n",
    "                    ln = fns.most_common()[0][0]\n",
    "            # only \n",
    "            gender = ''\n",
    "            if j['gender']==['WIKI_Q6581097']:\n",
    "                gender = 'm'\n",
    "            elif j['gender']==['WIKI_Q6581072']:\n",
    "                gender = 'f'\n",
    "            \n",
    "            if False and not fn or not ln:\n",
    "                if ',' in namel:\n",
    "                    if ' ' in namel.split(',')[0].strip():\n",
    "                        namel = namel.split(',')[0].strip()\n",
    "                    else:\n",
    "                        namel = namel.split(',')[1].strip()+' '+namel.split(',')[0].strip()\n",
    "                    #print(name, namel)\n",
    "                parts = namel.split(' ')\n",
    "                if len(parts) == 1 and fn:\n",
    "                    if namel.startswith(fn):\n",
    "                        parts = [fn, namel[len(fn):]]\n",
    "                    elif namel.endswith(fn):\n",
    "                        parts = [fn, namel[:len(namel)-len(fn)]]\n",
    "                if len(parts) == 1 and ln:\n",
    "                    if namel.startswith(ln):\n",
    "                        parts = [namel[len(ln):], ln]\n",
    "                    elif namel.endswith(ln):\n",
    "                        parts = [namel[:len(namel)-len(ln)], ln]\n",
    "\n",
    "                if len(parts) == 2:\n",
    "                    if fn and parts[0]==fn:\n",
    "                        ln = parts[1]\n",
    "                    elif fn and parts[1]==fn:\n",
    "                        ln = parts[0]\n",
    "                    elif ln and parts[1]==ln:\n",
    "                        fn = parts[0]\n",
    "                    elif ln and parts[0]==ln:\n",
    "                        fn = parts[1]\n",
    "                    else:\n",
    "                        fn, ln = parts\n",
    "                elif len(parts) > 2:\n",
    "                    fn, ln = parts[0], parts[-1]\n",
    "                    \n",
    "            if not cc:\n",
    "                cc = ''\n",
    "\n",
    "            desc_en = qid_en_desc_get(qid)\n",
    "            for q in j['positions']:\n",
    "                desc_nl = list(qid_lab_get(int(q[6:]), native_lang, include_alt=False).keys())\n",
    "                desc_nl = desc_nl[0] if desc_nl else ''\n",
    "\n",
    "                if desc_nl:\n",
    "                    break\n",
    "\n",
    "\n",
    "            fo.write(f'{qid}\\t{name}\\t{fn}\\t{ln}\\t{gender}\\t{cc}\\t{native_lang}\\t{ccs}\\t{desc_en}\\t{desc_nl}\\t{dob}\\t{dod}\\t{image}\\t{sort}\\n')\n",
    "    #if i>100:\n",
    "    #    break\n",
    "fo.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open('/backup/wikidata/wiki_parsed.tsv', 'w')\n",
    "fi = open('/backup/wikidata/wiki_person.tsv', 'r')\n",
    "fi.readline()\n",
    "fo.write(f\"qid\\tname\\tprob\\ttitle\\tfn\\tln\\tfn_org\\tln_org\\n\") \n",
    "\n",
    "for i, l in tqdm(enumerate(fi), total=9928121 ):\n",
    "    qid, name, fn_org, ln_org, gender, desc, cc, dob, image, sort = l.strip('\\n').split('\\t')\n",
    "    rec = parse(name)\n",
    "    titles, fn, ln = [], [], []\n",
    "    prob = -1 \n",
    "    if rec['tags'] and rec['tags'][0]['prob']>0.2:\n",
    "        prob = rec['tags'][0]['prob']\n",
    "        for tok, typ in zip(rec['tags'][0]['tokens'], rec['tags'][0]['labels']):\n",
    "            if typ[:5] == 'title':\n",
    "                titles.append(tok)\n",
    "            elif typ[:2] == 'fn':\n",
    "                fn.append(tok)\n",
    "            elif typ[:2] == 'ln':\n",
    "                ln.append(tok)\n",
    "    fo.write(f\"{qid}\\t{name}\\t{prob}\\t{','.join(titles)}\\t{','.join(fn)}\\t{','.join(ln)}\\t{fn_org}\\t{ln_org}\\n\") \n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2054c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l /backup/wikidata/wiki_person.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a3c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk = 0\n",
    "fn = '/projekti/mondonomo/books/thai/thai_wiki.csv'\n",
    "fo = open(fn, 'w')\n",
    "fo2 = open(fn.replace('thai_', 'nonthai_'), 'w')\n",
    "for i, l in enumerate(open('/backup/wikidata/wiki_person.jsonl')):\n",
    "    j = json.loads(l)\n",
    "    cc = get_wiki_cc(j['country'], j['birth_place'], j['language'])\n",
    "    if 'en' in j['l'] and 'th' in j['l'] and cc:\n",
    "        native = j[\"name_native\"][0] if j[\"name_native\"] else ''\n",
    "        en = j[\"l\"][\"en\"][0].replace(',',' ')\n",
    "        th = j[\"l\"][\"th\"][0].replace(',',' ')\n",
    "        if cc == 'TH':\n",
    "            fo.write(f'{j[\"id\"]},{cc},{en},{th}\\n')\n",
    "        else:\n",
    "            fo2.write(f'{j[\"id\"]},{cc},{en},{th}\\n')\n",
    "        uk += 1\n",
    "fo.close()\n",
    "!head /projekti/mondonomo/books/thai/thai_wiki.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "uk = 0\n",
    "fn = '/backup/wikidata/hr_wiki.csv'\n",
    "fo = open(fn, 'w')\n",
    "fo2 = open(fn.replace('hr_', 'nonhr_'), 'w')\n",
    "for l in tqdm(open('/backup/wikidata/wiki_person.jsonl'), total=10_044_571):\n",
    "    j = json.loads(l)\n",
    "    cc = get_wiki_cc(j['country'], j['birth_place'], j['language'])\n",
    "    if 'en' in j['l'] and 'hr' in j['l'] and cc:\n",
    "        native = j[\"name_native\"][0] if j[\"name_native\"] else ''\n",
    "        en = j[\"l\"][\"en\"][0].replace(',',' ')\n",
    "        th = j[\"l\"][\"hr\"][0].replace(',',' ')\n",
    "        if cc == 'HR':\n",
    "            fo.write(f'{j[\"id\"]},{cc},{en},{th}\\n')\n",
    "        else:\n",
    "            fo2.write(f'{j[\"id\"]},{cc},{en},{th}\\n')\n",
    "        uk += 1\n",
    "fo.close()\n",
    "!head $fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5598f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse('George Washington')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
