{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6496649c-8829-4028-bb41-63a9adb6c319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('US', 'BE', 93, {'de'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wiki_location import q2cc\n",
    "WIKI_DIR = '/backup/wikidata'\n",
    "api_key = open('airtable_key.txt').read()\n",
    "from pyairtable import Table, Api\n",
    "import sys\n",
    "sys.path.insert(0, '/projekti/nelma')\n",
    "from mondoDB.referencedb import provi\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "if True:\n",
    "    lang2cc = defaultdict(Counter)\n",
    "    for k, v in provi.items():\n",
    "        lang, s, c = v['id'].split('_')\n",
    "        bod = float(v['Percent']) if 'Percent' in v else 0\n",
    "        if 'Status' in v:\n",
    "            if v['Status'] == 'official':\n",
    "                bod += 1\n",
    "            elif v['Status'] == 'official_regional':\n",
    "                bod += 0.5\n",
    "            elif v['Status'] == 'de_facto_official':\n",
    "                bod += 0.9\n",
    "            elif v['Status'] == 'romanized':\n",
    "                bod += 0.2\n",
    "            elif v['Status'] == 'foreign':\n",
    "                bod += -0.5\n",
    "        if bod>1.1:\n",
    "            lang2cc[f'{lang}'][c] = max(bod, lang2cc[f'{lang}'][c])\n",
    "    api = Api(api_key)\n",
    "    w2iso = {t['fields']['WMF']: t['fields']['qid'] if 'qid' in t['fields'] else None for t in Table(api_key, 'appUZvAm9EHZgC1Eg', 'wiki_lang').all()}\n",
    "    wiki2cc = defaultdict(Counter)\n",
    "    for k, v in w2iso.items():\n",
    "        if len(k) == 2:\n",
    "            wiki2cc[v].update(lang2cc[k])\n",
    "        elif k.count('-') == 1:\n",
    "            a, b = k.split('-')\n",
    "            if len(a) == 2 and len(b) == 2:\n",
    "                wiki2cc[v][b.upper()] += 5 \n",
    "            elif len(a) == 2 and len(b) == 4:\n",
    "                #wiki2cc[v].update(lang2cc[f'{k}_{b.uppser()}'])\n",
    "                wiki2cc[v].update(lang2cc[a])\n",
    "    wikil2cc = {k: {cc: round(100*v2/max(v.values())) for cc, v2 in v.items()} for k, v in wiki2cc.items() if len(v)>0 and max(v.values())>0}\n",
    "\n",
    "cc2lang = defaultdict(set)\n",
    "for lang, ccs in lang2cc.items():\n",
    "    for cc in ccs:\n",
    "        if ccs[cc]>1.4:\n",
    "            cc2lang[cc].add(lang)\n",
    "iso2w = {k:v for v, k in w2iso.items()}\n",
    "\n",
    "q2cc['Q95'], q2cc['Q31'], wikil2cc['Q1860']['US'], cc2lang['CH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0eaa5-dcf0-47d4-8d5a-2603cc434ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a363ac148ca6407aa4a5733181a32188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10618668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "prvo = True\n",
    "fo = open('/backup/wikidata/sehr.csv', 'w')\n",
    "for l in tqdm(open('/backup/wikidata/wiki_person.jsonl'), total=10_618_668):\n",
    "    j = json.loads(l)\n",
    "    d = {'qid': j['id'], 'name_hr': j['l']['hr'] if 'hr' in j['l'] else '', 'name_se': j['l']['se'] if 'se' in j['l'] else '', \n",
    "         'name_en': j['l']['en'] if 'en' in j['l'] else '', 'desc_en': j['desc']['en'] if 'en' in j['desc'] else '',\n",
    "         'desc_sv': j['desc']['en'] if 'en' in j['desc'] else '',\n",
    "        }\n",
    "    se = False\n",
    "    hr = False\n",
    "    for k in ['country residence', 'birth_place', 'place of death burial', 'educated at', 'work location', 'employer', 'language']:\n",
    "        ccs = set()\n",
    "        for v in j[k]:\n",
    "            v = v.replace('WIKI_','')\n",
    "            if k != 'language':\n",
    "                if v in q2cc:\n",
    "                    ccs.add(q2cc[v])\n",
    "            else:\n",
    "                if v in wikil2cc:\n",
    "                    ccs.update(wikil2cc[v])\n",
    "        if 'HR' in ccs:\n",
    "            hr = True\n",
    "        if 'SE' in ccs:\n",
    "            se = True\n",
    "        d[k] = list(ccs)\n",
    "    d['hrwiki'] = 'hrwiki' in j['sitelinks']\n",
    "    d['swwiki'] = 'svwiki' in j['sitelinks']\n",
    "    if (se and hr) or (se and d['hrwiki'] and not d['swwiki']) or (hr and not d['hrwiki'] and d['swwiki']):\n",
    "        if prvo:\n",
    "            fo.write('\\t'.join(d.keys()))\n",
    "            fo.write('\\n')\n",
    "            prvo = False\n",
    "        fo.write('\\t'.join([str(a) for a in d.values()]))\n",
    "        fo.write('\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a22033c-ea15-4c93-b1a8-3aaa57c6b9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 /backup/wikidata/sehr.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l /backup/wikidata/sehr.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
