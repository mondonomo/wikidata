{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6496649c-8829-4028-bb41-63a9adb6c319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('US', 'BE', 93, {'de'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wiki_location import q2cc\n",
    "WIKI_DIR = '/backup/wikidata'\n",
    "api_key = open('airtable_key.txt').read()\n",
    "from pyairtable import Table, Api\n",
    "import sys\n",
    "sys.path.insert(0, '/projekti/nelma')\n",
    "from mondoDB.referencedb import provi\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "if True:\n",
    "    lang2cc = defaultdict(Counter)\n",
    "    for k, v in provi.items():\n",
    "        lang, s, c = v['id'].split('_')\n",
    "        bod = float(v['Percent']) if 'Percent' in v else 0\n",
    "        if 'Status' in v:\n",
    "            if v['Status'] == 'official':\n",
    "                bod += 1\n",
    "            elif v['Status'] == 'official_regional':\n",
    "                bod += 0.5\n",
    "            elif v['Status'] == 'de_facto_official':\n",
    "                bod += 0.9\n",
    "            elif v['Status'] == 'romanized':\n",
    "                bod += 0.2\n",
    "            elif v['Status'] == 'foreign':\n",
    "                bod += -0.5\n",
    "        if bod>1.1:\n",
    "            lang2cc[f'{lang}'][c] = max(bod, lang2cc[f'{lang}'][c])\n",
    "    api = Api(api_key)\n",
    "    w2iso = {t['fields']['WMF']: t['fields']['qid'] if 'qid' in t['fields'] else None for t in Table(api_key, 'appUZvAm9EHZgC1Eg', 'wiki_lang').all()}\n",
    "    wiki2cc = defaultdict(Counter)\n",
    "    for k, v in w2iso.items():\n",
    "        if len(k) == 2:\n",
    "            wiki2cc[v].update(lang2cc[k])\n",
    "        elif k.count('-') == 1:\n",
    "            a, b = k.split('-')\n",
    "            if len(a) == 2 and len(b) == 2:\n",
    "                wiki2cc[v][b.upper()] += 5 \n",
    "            elif len(a) == 2 and len(b) == 4:\n",
    "                #wiki2cc[v].update(lang2cc[f'{k}_{b.uppser()}'])\n",
    "                wiki2cc[v].update(lang2cc[a])\n",
    "    wikil2cc = {k: {cc: round(100*v2/max(v.values())) for cc, v2 in v.items()} for k, v in wiki2cc.items() if len(v)>0 and max(v.values())>0}\n",
    "\n",
    "cc2lang = defaultdict(set)\n",
    "for lang, ccs in lang2cc.items():\n",
    "    for cc in ccs:\n",
    "        if ccs[cc]>1.4:\n",
    "            cc2lang[cc].add(lang)\n",
    "iso2w = {k:v for v, k in w2iso.items()}\n",
    "\n",
    "q2cc['Q95'], q2cc['Q31'], wikil2cc['Q1860']['US'], cc2lang['CH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0eaa5-dcf0-47d4-8d5a-2603cc434ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a363ac148ca6407aa4a5733181a32188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10618668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "prvo = True\n",
    "fo = open('/backup/wikidata/sehr.csv', 'w')\n",
    "for l in tqdm(open('/backup/wikidata/wiki_person.jsonl'), total=10_618_668):\n",
    "    j = json.loads(l)\n",
    "    d = {'qid': j['id'], 'name_hr': j['l']['hr'] if 'hr' in j['l'] else '', 'name_se': j['l']['se'] if 'se' in j['l'] else '', \n",
    "         'name_en': j['l']['en'] if 'en' in j['l'] else '', 'desc_en': j['desc']['en'] if 'en' in j['desc'] else '',\n",
    "         'desc_sv': j['desc']['en'] if 'en' in j['desc'] else '',\n",
    "        }\n",
    "    se = False\n",
    "    hr = False\n",
    "    for k in ['country residence', 'birth_place', 'place of death burial', 'educated at', 'work location', 'employer', 'language']:\n",
    "        ccs = set()\n",
    "        for v in j[k]:\n",
    "            v = v.replace('WIKI_','')\n",
    "            if k != 'language':\n",
    "                if v in q2cc:\n",
    "                    ccs.add(q2cc[v])\n",
    "            else:\n",
    "                if v in wikil2cc:\n",
    "                    ccs.update(wikil2cc[v])\n",
    "        if 'HR' in ccs:\n",
    "            hr = True\n",
    "        if 'SE' in ccs:\n",
    "            se = True\n",
    "        d[k] = list(ccs)\n",
    "    d['hrwiki'] = 'hrwiki' in j['sitelinks']\n",
    "    d['swwiki'] = 'svwiki' in j['sitelinks']\n",
    "    if (se and hr) or (se and d['hrwiki'] and not d['swwiki']) or (hr and not d['hrwiki'] and d['swwiki']):\n",
    "        if prvo:\n",
    "            fo.write('\\t'.join(d.keys()))\n",
    "            fo.write('\\n')\n",
    "            prvo = False\n",
    "        fo.write('\\t'.join([str(a) for a in d.values()]))\n",
    "        fo.write('\\n')\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a22033c-ea15-4c93-b1a8-3aaa57c6b9b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/backup/wikidata/wiki_person.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m prvo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m fo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/backup/wikidata/ushr.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/backup/wikidata/wiki_person.jsonl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10_618_668\u001b[39m):\n\u001b[1;32m      6\u001b[0m     j \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(l)\n\u001b[1;32m      7\u001b[0m     d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m: j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_hr\u001b[39m\u001b[38;5;124m'\u001b[39m: j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname_en\u001b[39m\u001b[38;5;124m'\u001b[39m: j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc_en\u001b[39m\u001b[38;5;124m'\u001b[39m: j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc_sv\u001b[39m\u001b[38;5;124m'\u001b[39m: j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m         }\n",
      "File \u001b[0;32m/projekti/venv311/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/backup/wikidata/wiki_person.jsonl'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "prvo = True\n",
    "fo = open('/backup/wikidata/ushr.csv', 'w')\n",
    "for l in tqdm(open('/backup/wikidata/wiki_person.jsonl'), total=10_618_668):\n",
    "    j = json.loads(l)\n",
    "    d = {'qid': j['id'], 'name_hr': j['l']['hr'] if 'hr' in j['l'] else '', \n",
    "         'name_en': j['l']['en'] if 'en' in j['l'] else '', 'desc_en': j['desc']['en'] if 'en' in j['desc'] else '',\n",
    "         'desc_sv': j['desc']['en'] if 'en' in j['desc'] else '',\n",
    "        }\n",
    "    se = False\n",
    "    hr = False\n",
    "    for k in ['country residence', 'birth_place', 'place of death burial', 'educated at', 'work location', 'employer', 'language']:\n",
    "        ccs = set()\n",
    "        for v in j[k]:\n",
    "            v = v.replace('WIKI_','')\n",
    "            if k != 'language':\n",
    "                if v in q2cc:\n",
    "                    ccs.add(q2cc[v])\n",
    "            else:\n",
    "                if v in wikil2cc:\n",
    "                    ccs.update(wikil2cc[v])\n",
    "        if 'HR' in ccs:\n",
    "            hr = True\n",
    "        if 'US' in ccs:\n",
    "            se = True\n",
    "        d[k] = list(ccs)\n",
    "    d['hrwiki'] = 'hrwiki' in j['sitelinks']\n",
    "    d['uswiki'] = 'svwiki' in j['sitelinks']\n",
    "    if (se and hr) or (se and d['hrwiki'] and not d['swwiki']) or (hr and not d['hrwiki'] and d['swwiki']):\n",
    "        if prvo:\n",
    "            fo.write('\\t'.join(d.keys()))\n",
    "            fo.write('\\n')\n",
    "            prvo = False\n",
    "        fo.write('\\t'.join([str(a) for a in d.values()]))\n",
    "        fo.write('\\n')\n",
    "    break\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4b5d2-287b-4cb1-8f68-584b0ec925c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "prvo = True\n",
    "fo = open('/backup/wikidata/lvhr.csv', 'w')\n",
    "for l in tqdm(open('/backup/wikidata/wiki_person.jsonl'), total=10_618_668):\n",
    "    j = json.loads(l)\n",
    "    d = {'qid': j['id'], 'name_hr': j['l']['hr'] if 'hr' in j['l'] else '', \n",
    "         'name_en': j['l']['en'] if 'en' in j['l'] else '', 'desc_en': j['desc']['en'] if 'en' in j['desc'] else '',\n",
    "         'desc_sv': j['desc']['en'] if 'en' in j['desc'] else '',\n",
    "        }\n",
    "    se = False\n",
    "    hr = False\n",
    "    for k in ['country residence', 'birth_place', 'place of death burial', 'educated at', 'work location', 'employer', 'language']:\n",
    "        ccs = set()\n",
    "        for v in j[k]:\n",
    "            v = v.replace('WIKI_','')\n",
    "            if k != 'language':\n",
    "                if v in q2cc:\n",
    "                    ccs.add(q2cc[v])\n",
    "            else:\n",
    "                if v in wikil2cc:\n",
    "                    ccs.update(wikil2cc[v])\n",
    "        if 'HR' in ccs:\n",
    "            hr = True\n",
    "        if 'US' in ccs:\n",
    "            se = True\n",
    "        d[k] = list(ccs)\n",
    "    d['hrwiki'] = 'hrwiki' in j['sitelinks']\n",
    "    d['lvwiki'] = 'lvwiki' in j['sitelinks']\n",
    "    if (se and hr) or (se and d['hrwiki'] and not d['lvwiki']) or (hr and not d['lvwiki'] and d['lvwiki']):\n",
    "        if prvo:\n",
    "            fo.write('\\t'.join(d.keys()))\n",
    "            fo.write('\\n')\n",
    "            prvo = False\n",
    "        fo.write('\\t'.join([str(a) for a in d.values()]))\n",
    "        fo.write('\\n')\n",
    "fo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
